# Text-to-Image Generator with Stable Diffusion

This project uses **Stable Diffusion**, a state-of-the-art deep learning model, to generate images from text prompts. Given any text input, the model creates a corresponding image that visually represents the description.

---

## Features

- Generate high-quality images from any user-provided text prompt
- Powered by the Stable Diffusion v1-4 model by CompVis
- Utilizes GPU acceleration for faster image generation (via CUDA)
- Easy-to-use command-line interface for inputting prompts
- Displays the generated image inline (for Jupyter Notebook / IPython environments)

---

## Requirements

- Python 3.7 or higher
- A CUDA-enabled GPU for best performance (optional but highly recommended)
- diffusers, transformers, accelerate Python packages

---

## About Stable Diffusion

Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. It was developed by CompVis and released to promote accessible AI-generated art.

---

## Example Output

![Screenshot 2025-05-24 at 7 14 47â€¯PM](https://github.com/user-attachments/assets/1f20aeec-7139-4a6e-96e9-06508384e7cb)

---

